<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[任务型对话系统的用户模拟器]]></title>
    <url>%2F2019%2F05%2F04%2Fusersim%2F</url>
    <content type="text"><![CDATA[原文链接 论文概述&emsp;&emsp;作者总结了前人构造用户模拟器方法，提出了一个比较通用的用户模拟器的框架，并且还有开源的源码，既包含基于规则又有基于模型的。 相关工作介绍&emsp;&emsp;用户模拟器的构造一直是一个争议的问题，没有一个普遍可接受的标准，但是一个好的用户模拟器的重要的特征必须是在整个对话过程中具有连贯的行为。理想情况下，一个好的度量标准应该度量用户模拟器和真实人类行为之间的相关性，但是很难找到一个被广泛接受的度量标准。因此，没有标准的方法来构建用户模拟器。但可以从两方面来总结用户模拟器相关的文献: 从 粒度 层面上来说，用户模拟器可以分为对话行为级别和语言级别 从 方法 层面上来说，用户模拟器分为基于规则的和基于模型的（从训练数据中学习得到） 过去方法&emsp;&emsp;早期的模型有基于bi-gram的,利用$P(a_{u}|a_{m})$基于上一次系统行为去选择用户行为，但是比较不合理，有两点原因：1.这个模型只能看到最后一个系统行为。 2. 如果用户切换意图那么这个模型可能产出不和逻辑的行为，因为它没有把意图考虑进去。关这个方法的后续工作中，有很多工作都试图解决这些问题。问题1 可以通过查看更长的对话历史记录来选择下一个用户动作来解决;问题2 可以通过显式地将用户目标合并到用户状态建模中来解决。 &emsp;&emsp;基于seq2seq的方式通过端到端的方法来模拟用户，这种方法把用户和系统的对话当做 源到端 的序列生成问题，可能更适合类似于chat-bot的类型，不太合适任务型对话，而且需要大量数据 &emsp;&emsp; agenda-based 基于议程的用户模拟器提供一种方便的机制来显式编码对话历史和用户目标。用户目标goal由描述用户请求request和约束的slot-value对组成。对话状态由一个类似堆栈的格式表示，用户行为生成为一系列简单的push和pop操作，确保用户在会话过程中行为的一致性。 本文方法&emsp;&emsp;这篇文章结合seq2seq的方法和基于agenda-based的方法，在对话行为层面用agenda-based的方法，然后用一个seq2seq的方法来将对话行为翻译成自然语言的形式。 用户模拟器介绍&emsp;&emsp;agenda-based的方法，利用栈来表示用户状态（包含对话历史和用户行为),状态更新（包含状态转换和用户行为生成）用栈的pop、push来建模。下面详细描述一个基于规则的用户模拟器。 用户目标&emsp;&emsp;对话的第一步是生成用户目标，用户目标包含两个部分： inform_slots 包含一些 slot value 对作为限制 request_slots 包含一个slot集合 ，这个集合表示用户未知，但是在接下来的对话中想知道的。 &emsp;&emsp;为了让目标更真实，加入一些限制规则：slot将被分为两组。对于买电影票场景，一些元素必须出现在用户目标中，称作 Required slots，包含 moviename, theater, starttime, date, number of people;剩下的元素作为可选项。ticket 是默认出现在request_slots部分的slot。 &emsp;&emsp;从已标注的数据中生成用户目标，主要采用两种方法： 从用户第一轮问句（打招呼的问句除外）中检测所有的槽（已知或未知）组建用户目标，因为第一句往往包含了用户所有的需求。 从所有用户轮问题中提取所有的槽（以第一次出现为准），组建用户目标 &emsp;&emsp;把得到的用户目标存在用户目标数据库中，每次运行一个对话就从中随机选取一个。 用户行为&emsp;&emsp; 第一个用户行为： 这个工作关注用户行为的初始化，当我们随机选取一个用户目标时，为了保证真实性，在生成时需要加一些规则限制。比如，第一轮往往是request 行为，至少包含一个 informable slot，如果该意图知道电影名，那么moviename 必须出现在首轮，等； &emsp;&emsp;用户状态status $s_{u}$被分解为$agenda A$ 和 $goal G$,其中 G 由两部分组成(C,R)分别表示 限制C和请求R。在每一个时间t，用户模拟器将会根据当前状态$s_{u,t}$和上个系统动作$a_{m,t-1}$生成下一个用户行为$a_{u,t}$,然后更新当前用户状态$s^{‘}_{u,t}$。 &emsp;&emsp;没有NLU（自然语言理解）模块下，作者引入噪音模型来模拟NLU模块的失误。有两个级别的错误，意图级别的识别失误和slot级别的失误。slot有3中类型错误： slot deletion：槽未识别 incorrect slot value：槽对槽值错 incorrect slot：槽错 &emsp;&emsp;如果代理动作是inform(taskcomplete)，则表示代理已经收集了所有信息并准备好预订电影票。用户模拟器将检查当前堆栈是否为空，并执行约束检查，以确保代理试图预订正确的电影票。这确保用户以一致的、面向目标的方式进行操作。 对话状态&emsp;&emsp;总共有3种状态：未结束，成功，失败。当agent不是inform(taskcomplete) 或者对话轮数没有超过阈值时状态都是 未结束 。完全满足条件则是超过，否则失败。 &emsp;&emsp;有一个特殊情况，如果识别完全正确但数据库中没有，本文依然判断为失败。 NLU&emsp;&emsp;使用一个LSTM网络joint 的训练intent识别和预测标签。 标签用IOB的方式标记，每句的结尾加上。 NLG&emsp;&emsp;本文采取了一个混合模板和模型的方法来实现NLG Template-based NLG：对于每个对话行为采用预定义的模板 Model-based NLG：输入用户行为，通过一个LSTM decoder生成一个带slot placeholders的句子，后文再用真实的slot value 填充placeholders的值。在 LSTM decoder中采用 beam search（集束搜索）,beam 的大小为3. &emsp;&emsp;如果对话行为能在预定义的规则模板中找到，则使用基于模板的NLG去生成，采用基于模型的方式。 使用&emsp;&emsp;要度量代理的效果，有3个参数：{成功率，平均奖励，平均轮数}，它们都提供了关于代理质量的不同信息。一般而言他们3个是强相关的，一个好的代理同时具有这3方面比较优秀的数字。]]></content>
      <categories>
        <category>对话系统，用户模拟器</category>
      </categories>
      <tags>
        <tag>对话系统</tag>
        <tag>用户模拟器</tag>
        <tag>自然语言生成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分治]]></title>
    <url>%2F2019%2F05%2F01%2F19-5-1-leetcode%2F</url>
    <content type="text"><![CDATA[题目1. 求 Pow(x,n)no.50 题目简介：&emsp;&emsp;求pow(x,n) ,时间复杂度要小。 题解：&emsp;&emsp;首先 n可能有正负，所以分两种情况处理 return 1/ Pow(x,-n,map)和 return Pow(x,n,map); 在计算pow的时候 根据n是奇数或者是偶数来进行分治。用map记录已经计算过的值，减少递归的数量级。 代码：1234567891011121314151617181920212223242526272829303132​class Solution &#123; public double myPow(double x, int n) &#123; Map&lt;Integer,Double&gt; map = new HashMap&lt;&gt;(); if(n &lt;0)&#123; return 1/ Pow(x,-n,map); &#125;else&#123; return Pow(x,n,map); &#125; &#125; double Pow(double x, int n,Map&lt;Integer,Double&gt; map)&#123; if (n ==0)return 1; if(n == 1)return x; if(n == 2)return x*x; if(map.get(n) != null)&#123; //计算过了就直接返回 return map.get(n); &#125;else&#123; Double t=0.0; if(n %2 == 0)&#123; t = Pow(x,n/2,map)*Pow(x,n/2,map); //n为偶数 &#125;else&#123; t = Pow(x,n/2,map)*Pow(x,n/2,map)*x; //n为奇数 &#125; map.put(n,t); //没计算过就存起来 return t; &#125; &#125;&#125;​]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>分治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Test]]></title>
    <url>%2F2019%2F04%2F30%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment 数学 f(x) = a_1x^n + a_2x^{n-1} + a_3x^{n-2}公式显示错误https://www.jianshu.com/p/49538f7d9512]]></content>
  </entry>
</search>
